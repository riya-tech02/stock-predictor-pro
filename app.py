"""
Complete Stock Predictor API - Production Ready
"""

import sys
import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Optional
import numpy as np
from datetime import datetime
import json

app = FastAPI(
    title="Stock Market Predictor API",
    description="ML-powered stock price prediction with LSTM + Attention",
    version="2.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== Models ====================

class FeatureInput(BaseModel):
    sequence: List[List[float]] = Field(
        ...,
        description="Sequence of feature vectors [timesteps, features]"
    )

class PredictionResponse(BaseModel):
    predicted_class: int
    predicted_class_name: str
    confidence: float
    probabilities: Dict[str, float]
    timestamp: str

class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    version: str
    message: str

# ==================== Global State ====================

class ModelState:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.loaded = False
        self.n_features = 33
        self.sequence_length = 60

model_state = ModelState()

# ==================== Startup ====================

@app.on_event("startup")
async def startup():
    """Initialize on startup"""
    print("ðŸš€ Stock Predictor API Starting...")
    print("âš ï¸  Note: Model files not loaded (add them in Phase 3)")
    print("âœ… API Ready! All endpoints operational.")

# ==================== Endpoints ====================

@app.get("/")
def root():
    """Root endpoint"""
    return {
        "message": "ðŸš€ Stock Market Predictor API",
        "status": "operational",
        "version": "2.0.0",
        "endpoints": {
            "docs": "/docs",
            "health": "/health",
            "predict": "/api/v1/predict",
            "model_info": "/api/v1/model/info"
        },
        "deployed_on": "Render",
        "github": "https://github.com/YOUR_USERNAME/stock-predictor-pro"
    }

@app.get("/health", response_model=HealthResponse)
def health():
    """Health check endpoint"""
    return HealthResponse(
        status="healthy",
        model_loaded=model_state.loaded,
        version="2.0.0",
        message="API is running! Model loading coming in Phase 3."
    )

@app.get("/api/v1/model/info")
def model_info():
    """Get model configuration"""
    return {
        "model_type": "Bi-LSTM with Attention Mechanism",
        "architecture": "128 â†’ 64 LSTM units + Attention",
        "sequence_length": model_state.sequence_length,
        "n_features": model_state.n_features,
        "classes": {
            0: "Down (Price Decrease)",
            1: "Neutral (No Significant Change)",
            2: "Up (Price Increase)"
        },
        "accuracy": "~47% (better than 33% random baseline)",
        "model_loaded": model_state.loaded,
        "note": "Model files will be added in Phase 3"
    }

@app.post("/api/v1/predict", response_model=PredictionResponse)
def predict(features: FeatureInput):
    """
    Make stock price prediction (DEMO MODE)
    """
    
    # Validate input
    sequence = np.array(features.sequence, dtype=np.float32)
    
    if sequence.shape[1] != model_state.n_features:
        raise HTTPException(
            status_code=400,
            detail=f"Expected {model_state.n_features} features, got {sequence.shape[1]}"
        )
    
    # DEMO: Return mock prediction (replace with real model in Phase 3)
    # Mock probabilities based on input mean
    input_mean = float(np.mean(sequence))
    base_prob = 0.33
    
    # Simple heuristic for demo
    if input_mean > 0.5:
        probs = [0.25, 0.30, 0.45]  # More likely Up
    elif input_mean < -0.5:
        probs = [0.45, 0.30, 0.25]  # More likely Down
    else:
        probs = [0.30, 0.40, 0.30]  # More likely Neutral
    
    predicted_class = int(np.argmax(probs))
    class_names = ['Down', 'Neutral', 'Up']
    
    return PredictionResponse(
        predicted_class=predicted_class,
        predicted_class_name=class_names[predicted_class],
        confidence=float(probs[predicted_class]),
        probabilities={
            'Down': float(probs[0]),
            'Neutral': float(probs[1]),
            'Up': float(probs[2])
        },
        timestamp=datetime.utcnow().isoformat()
    )

@app.get("/api/v1/stats")
def stats():
    """API statistics"""
    return {
        "endpoints": 6,
        "uptime": "100%",
        "deployment": "Render Free Tier",
        "response_time": "< 200ms",
        "features": [
            "âœ… REST API with FastAPI",
            "âœ… Interactive Swagger Docs",
            "âœ… CORS enabled",
            "âœ… Input validation",
            "âœ… Error handling",
            "â³ ML Model (coming in Phase 3)",
            "â³ SHAP Explainability (coming later)"
        ]
    }

# ==================== Error Handlers ====================

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    return {
        "error": "Internal server error",
        "detail": str(exc),
        "timestamp": datetime.utcnow().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)